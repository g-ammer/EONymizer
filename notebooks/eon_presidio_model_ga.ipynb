{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dso1gYbLj9e2"
   },
   "source": [
    "# Install dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sL-OHRXsj78v"
   },
   "source": [
    "# Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "import helper_functions_presidio as hfp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.lang.de.German at 0x26cf318aa10>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "spacy.load('de_core_news_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pytz\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load .txt files from local folder and convert to dictionary\n",
    "directory_path = '../data/original_texts_renamed/'\n",
    "original_texts_dict = hfp.convert_txt_to_dict(directory_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 441,
     "status": "ok",
     "timestamp": 1714390969341,
     "user": {
      "displayName": "Georg Ammer",
      "userId": "05376920440942557449"
     },
     "user_tz": -120
    },
    "id": "aF-bRVfe5DLR",
    "outputId": "1c9e5959-7874-4058-96e8-743e718d679b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check number of texts that were converted into dictionary\n",
    "len(original_texts_dict.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C_qPp1UrkIye"
   },
   "source": [
    "# Import Presidio libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "SMI44Yjwj2RU"
   },
   "outputs": [],
   "source": [
    "from presidio_analyzer import AnalyzerEngine, RecognizerRegistry, PatternRecognizer, EntityRecognizer, Pattern, RecognizerResult\n",
    "from presidio_analyzer.recognizer_registry import RecognizerRegistry\n",
    "from presidio_analyzer.nlp_engine import NlpEngineProvider\n",
    "from presidio_analyzer.context_aware_enhancers import LemmaContextAwareEnhancer\n",
    "from presidio_anonymizer import AnonymizerEngine\n",
    "from presidio_anonymizer.entities import OperatorConfig\n",
    "from presidio_anonymizer.entities import ConflictResolutionStrategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rvXnLsCWkZvp"
   },
   "source": [
    "## Define environment variables for Azure AI Language package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../credentials/azure_credentials.json') as config_file:\n",
    "    config = json.load(config_file)\n",
    "\n",
    "os.environ['AZURE_AI_ENDPOINT'] = config['azure_endpoint']\n",
    "os.environ['AZURE_AI_KEY'] = config['azure_key']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gdeQiV7dkx7E"
   },
   "source": [
    "## Initialize Presidio Analyzer with SpaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "PNkhb5yqkbPE"
   },
   "outputs": [],
   "source": [
    "# Load configuration file that specifies NLP engine and model for PresidioAnalyzer\n",
    "conf_file = \"../data/config_spacy_de.yml\"\n",
    "\n",
    "# Create NLP engine based on configuration\n",
    "provider = NlpEngineProvider(conf_file = conf_file)\n",
    "nlp_engine = provider.create_engine()\n",
    "\n",
    "# Initialize Recognizer registry\n",
    "registry = RecognizerRegistry()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G9AjGEXVcTVx"
   },
   "source": [
    "# Add Recognizers to registry\n",
    "### There are dozens of different Recognizers that can be called and added to the Presidio Analyzer, depending on the use-case. The Recognizers added here were specifically tailored to detect the entities that occured in the 1000 synthetic e-mails from E.ON. For texts with more or different entities, other Recognizers might need to be added. (For example, we didn't add a Recognizer for German IBAN numbers because they didn't occur in the texts and thus would potentially only add false positives.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 433,
     "status": "ok",
     "timestamp": 1714391465449,
     "user": {
      "displayName": "Georg Ammer",
      "userId": "05376920440942557449"
     },
     "user_tz": -120
    },
    "id": "Y_xnKZSWlKCd",
    "outputId": "af523dc6-51fe-4a70-cd4b-8bb20fe7e11d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ADDRESS', 'PERSON', 'EMAIL', 'LOCATION', 'PHONENUMBER']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add AzureAILanguageRecognizer to registry\n",
    "from presidio_analyzer.predefined_recognizers import AzureAILanguageRecognizer\n",
    "\n",
    "azure_ai_language = AzureAILanguageRecognizer(\n",
    "                                              supported_entities=[\"ADDRESS\", \"PERSON\", \"EMAIL\", \"LOCATION\", \"PHONENUMBER\"],\n",
    "                                              supported_language=\"de\"\n",
    "                                              )\n",
    "\n",
    "registry.add_recognizer(azure_ai_language)\n",
    "azure_ai_language.get_supported_entities()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 390,
     "status": "ok",
     "timestamp": 1714391472965,
     "user": {
      "displayName": "Georg Ammer",
      "userId": "05376920440942557449"
     },
     "user_tz": -120
    },
    "id": "ELhu4sR-lP8N",
    "outputId": "ce075066-45b4-457b-98d4-f04955933555"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DATE_TIME', 'NRP', 'LOCATION', 'PERSON', 'ORGANIZATION']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add SpacyRecognizer to registry\n",
    "from presidio_analyzer.predefined_recognizers import SpacyRecognizer\n",
    "\n",
    "spacy_recognizer_de = SpacyRecognizer(\n",
    "                                      supported_language=\"de\",\n",
    "                                      )\n",
    "\n",
    "registry.add_recognizer(spacy_recognizer_de)\n",
    "spacy_recognizer_de.get_supported_entities()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 378,
     "status": "ok",
     "timestamp": 1714391475337,
     "user": {
      "displayName": "Georg Ammer",
      "userId": "05376920440942557449"
     },
     "user_tz": -120
    },
    "id": "wyjwBBwulP6A",
    "outputId": "68732152-a99a-45d0-b0a8-029fe3e82e80"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PHONE_NUMBER']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add PhoneRecognizer to registry\n",
    "from presidio_analyzer.predefined_recognizers import PhoneRecognizer\n",
    "\n",
    "phone_recognizer_de = PhoneRecognizer(\n",
    "                                      supported_language=\"de\",\n",
    "                                      context=[\"telefon\", \"handy\", \"phone\" \"tel\", \"mobil\"]\n",
    "                                      )\n",
    "\n",
    "registry.add_recognizer(phone_recognizer_de)\n",
    "phone_recognizer_de.get_supported_entities()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "jRTB9XmhlP39"
   },
   "outputs": [],
   "source": [
    "# Build and add custom PatternRecognizers to registry\n",
    "\n",
    "# Define patterns for PatternRecognizers based on regex\n",
    "zaehlernr_pattern = Pattern(name=\"zaehlernr_pattern\", regex=\"(?<!\\d)\\d{7,12}(?!\\d)\", score = 0.5)\n",
    "vertragsnr_pattern = Pattern(name=\"vertragsnr_pattern\", regex=\"(?<!\\d)\\d{9,12}(?!\\d)\", score = 0.5)\n",
    "geschaftsnr_pattern = Pattern(name=\"geschaftsnr_pattern\", regex=\"(?<!\\d)\\d{9,12}(?!\\d)\", score = 0.5)\n",
    "rechnungsnr_pattern = Pattern(name=\"rechnungsnr_pattern\", regex=\"(?<!\\d)\\d{9,12}(?!\\d)\", score = 0.5)\n",
    "postlz_pattern = Pattern(name=\"postlz_pattern\", regex=\"(?<!\\d)\\d{5}(?!\\d)\", score = 0.45)\n",
    "strasse_pattern = Pattern(name=\"strasse_pattern\",\n",
    "                          regex=\"(^|\\s)[A-ZÄÖÜ][a-zäöüß\\- ]+ \\d{1,5}($|\\s)\", score = 0.4)\n",
    "\n",
    "# Build Recognizers\n",
    "zaehlernr_recognizer = PatternRecognizer(\n",
    "                                      supported_entity=\"ZAEHLERNR.\",\n",
    "                                      patterns = [zaehlernr_pattern],\n",
    "                                      context= [\"zählern\", \"zähler\", \"zahler\", \"hlernummer\", \"zaehler\"],\n",
    "                                      supported_language=\"de\"\n",
    "                                      )\n",
    "\n",
    "vertragsnr_recognizer = PatternRecognizer(\n",
    "                                      supported_entity=\"VERTRAGSNR.\",\n",
    "                                      patterns = [vertragsnr_pattern],\n",
    "                                      context= [\"vertragsnummer\", \"vertrag\"],\n",
    "                                      supported_language=\"de\"\n",
    "                                      )\n",
    "\n",
    "gpartnernr_recognizer = PatternRecognizer(\n",
    "                                      supported_entity=\"GESCHAEFTSPARTNERNR.\",\n",
    "                                      patterns = [geschaftsnr_pattern],\n",
    "                                      context= [\"geschäftspartnernummer\", \"geschäftspartner\", \"geschäft\", \"partner\", \"geschaefts\", \"kunden\"],\n",
    "                                      supported_language=\"de\"\n",
    "                                      )\n",
    "\n",
    "rechungsnr_recognizer = PatternRecognizer(\n",
    "                                      supported_entity=\"RECHNUNGSNR.\",\n",
    "                                      patterns = [rechnungsnr_pattern],\n",
    "                                      context= [\"rechnungsnummer\", \"rechnung\", \"echnung\"],\n",
    "                                      supported_language=\"de\"\n",
    "                                      )\n",
    "\n",
    "postlz_recognizer = PatternRecognizer(\n",
    "                                      supported_entity=\"PLZ\",\n",
    "                                      patterns = [postlz_pattern],\n",
    "                                      context= [\"postleitzahl\", \"strasse\", \"weg\", \"adresse\", \"plz\", \"platz\", \"gasse\", \"straße\"],\n",
    "                                      supported_language=\"de\"\n",
    "                                      )\n",
    "\n",
    "strasse_recognizer = PatternRecognizer(\n",
    "                                      supported_entity=\"STRASSE\",\n",
    "                                      patterns = [strasse_pattern],\n",
    "                                      context= [\"wohne\", \"adresse\", \"weg\", \"plz\"],\n",
    "                                      supported_language=\"de\"\n",
    "                                      )\n",
    "\n",
    "# Add PatternRecognizers to registry\n",
    "registry.add_recognizer(zaehlernr_recognizer)\n",
    "registry.add_recognizer(vertragsnr_recognizer)\n",
    "registry.add_recognizer(gpartnernr_recognizer)\n",
    "registry.add_recognizer(rechungsnr_recognizer)\n",
    "#registry.add_recognizer(postlz_recognizer)\n",
    "#registry.add_recognizer(strasse_recognizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "ZYg0VsSjpG6I"
   },
   "outputs": [],
   "source": [
    "# Add Deny List Recognizer with German City Names\n",
    "\n",
    "# Load txt file with German City names\n",
    "german_city_names = []\n",
    "with open('../data/german_cities_list.txt', 'r', encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        german_city_names.append(line.strip())\n",
    "\n",
    "cities_recognizer = PatternRecognizer(supported_entity = \"ORT\", supported_language=\"de\", deny_list = german_city_names)\n",
    "\n",
    "# This Recognizer produced many false positives and therefore was not added\n",
    "#registry.add_recognizer(cities_recognizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "4rtEGk3wlP1j"
   },
   "outputs": [],
   "source": [
    "# Initialize Presidio AnalyzerEngine with registry (containing Recognizers) and context_aware_enhancer\n",
    "\n",
    "context_aware_enhancer = LemmaContextAwareEnhancer(\n",
    "                                                  context_similarity_factor = 0.45,\n",
    "                                                  min_score_with_context_similarity = 0.5,\n",
    "                                                  context_prefix_count = 3,\n",
    "                                                  context_suffix_count = 0\n",
    "                                                  )\n",
    "\n",
    "analyzer_eon = AnalyzerEngine(\n",
    "                              registry = registry,\n",
    "                              nlp_engine = nlp_engine,\n",
    "                              supported_languages = [\"de\"],\n",
    "                              context_aware_enhancer = context_aware_enhancer,\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 394,
     "status": "ok",
     "timestamp": 1714391647099,
     "user": {
      "displayName": "Georg Ammer",
      "userId": "05376920440942557449"
     },
     "user_tz": -120
    },
    "id": "JAwCgaUmmImU",
    "outputId": "d2f77288-66ba-4635-ed20-24a72d614566"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['GESCHAEFTSPARTNERNR.', 'PHONE_NUMBER', 'EMAIL', 'ADDRESS', 'PERSON', 'PHONENUMBER', 'VERTRAGSNR.', 'ZAEHLERNR.', 'RECHNUNGSNR.', 'LOCATION']\n"
     ]
    }
   ],
   "source": [
    "# Print all supported entities for the PresidioAnalyzer named 'analyzer_eon'\n",
    "print(analyzer_eon.get_supported_entities())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 537,
     "status": "ok",
     "timestamp": 1714391648908,
     "user": {
      "displayName": "Georg Ammer",
      "userId": "05376920440942557449"
     },
     "user_tz": -120
    },
    "id": "YYoesotbmd2f",
    "outputId": "a2f2e96a-3bb2-414b-9f21-d03214c7668b"
   },
   "source": [
    "# Print all Recognizers for analyzer_eon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<presidio_analyzer.predefined_recognizers.phone_recognizer.PhoneRecognizer object at 0x0000021976727050>, <presidio_analyzer.pattern_recognizer.PatternRecognizer object at 0x000002194090B6D0>, <presidio_analyzer.predefined_recognizers.azure_ai_language.AzureAILanguageRecognizer object at 0x000002197671BCD0>, <presidio_analyzer.pattern_recognizer.PatternRecognizer object at 0x0000021976726F10>, <presidio_analyzer.pattern_recognizer.PatternRecognizer object at 0x000002193DFAE910>, <presidio_analyzer.pattern_recognizer.PatternRecognizer object at 0x0000021940952190>]\n"
     ]
    }
   ],
   "source": [
    "print(analyzer_eon.get_recognizers())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "1BO5lip_mnO-"
   },
   "outputs": [],
   "source": [
    "# Define list of entities that the PresidioAnalyzer should detect\n",
    "\n",
    "entities_to_detect = [\n",
    "                      'ADDRESS',\n",
    "                      'PHONENUMBER',\n",
    "                      'PHONE_NUMBER',\n",
    "                      'EMAIL',\n",
    "                      'RECHNUNGSNR.',\n",
    "                      'ZAEHLERNR.',\n",
    "                      'PERSON',\n",
    "                      'VERTRAGSNR.',\n",
    "                      'GESCHAEFTSPARTNERNR.',\n",
    "                      'LOCATION',\n",
    "                      'ORT'\n",
    "                     #'POSTLEITZAHL'\n",
    "                      ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "niaSJW5TveWe"
   },
   "source": [
    "# Run Presidio Analyzer on all texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 77961,
     "status": "ok",
     "timestamp": 1714392633701,
     "user": {
      "displayName": "Georg Ammer",
      "userId": "05376920440942557449"
     },
     "user_tz": -120
    },
    "id": "nve28nLWmuCV",
    "outputId": "07e5e233-01e1-4266-f439-124ae2d46da2"
   },
   "outputs": [
    {
     "ename": "HttpResponseError",
     "evalue": "(403) Out of call volume quota for TextAnalytics F0 pricing tier. Please retry after 12 days. To increase your call volume switch to a paid tier.\nCode: 403\nMessage: Out of call volume quota for TextAnalytics F0 pricing tier. Please retry after 12 days. To increase your call volume switch to a paid tier.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHttpResponseError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\EON\\Lib\\site-packages\\azure\\ai\\textanalytics\\_text_analytics_client.py:467\u001b[0m, in \u001b[0;36mTextAnalyticsClient.recognize_pii_entities\u001b[1;34m(self, documents, categories_filter, disable_service_logs, domain_filter, language, model_version, show_stats, string_index_type, **kwargs)\u001b[0m\n\u001b[0;32m    464\u001b[0m     models \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39mmodels(api_version\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_api_version)\n\u001b[0;32m    465\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[0;32m    466\u001b[0m         List[Union[RecognizePiiEntitiesResult, DocumentError]],\n\u001b[1;32m--> 467\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39manalyze_text(\n\u001b[0;32m    468\u001b[0m             body\u001b[38;5;241m=\u001b[39mmodels\u001b[38;5;241m.\u001b[39mAnalyzeTextPiiEntitiesRecognitionInput(\n\u001b[0;32m    469\u001b[0m                 analysis_input\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdocuments\u001b[39m\u001b[38;5;124m\"\u001b[39m: docs},\n\u001b[0;32m    470\u001b[0m                 parameters\u001b[38;5;241m=\u001b[39mmodels\u001b[38;5;241m.\u001b[39mPiiTaskParameters(\n\u001b[0;32m    471\u001b[0m                     logging_opt_out\u001b[38;5;241m=\u001b[39mdisable_service_logs,\n\u001b[0;32m    472\u001b[0m                     model_version\u001b[38;5;241m=\u001b[39mmodel_version,\n\u001b[0;32m    473\u001b[0m                     domain\u001b[38;5;241m=\u001b[39mdomain_filter,\n\u001b[0;32m    474\u001b[0m                     pii_categories\u001b[38;5;241m=\u001b[39mcategories_filter,\n\u001b[0;32m    475\u001b[0m                     string_index_type\u001b[38;5;241m=\u001b[39mstring_index_type_compatibility(string_index_type_arg)\n\u001b[0;32m    476\u001b[0m                 )\n\u001b[0;32m    477\u001b[0m             ),\n\u001b[0;32m    478\u001b[0m             show_stats\u001b[38;5;241m=\u001b[39mshow_stats,\n\u001b[0;32m    479\u001b[0m             \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m=\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcls\u001b[39m\u001b[38;5;124m\"\u001b[39m, pii_entities_result),\n\u001b[0;32m    480\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    481\u001b[0m         )\n\u001b[0;32m    482\u001b[0m     )\n\u001b[0;32m    484\u001b[0m \u001b[38;5;66;03m# api_versions 3.0, 3.1\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\EON\\Lib\\site-packages\\azure\\ai\\textanalytics\\_generated\\_operations_mixin.py:111\u001b[0m, in \u001b[0;36mTextAnalyticsClientOperationsMixin.analyze_text\u001b[1;34m(self, body, show_stats, **kwargs)\u001b[0m\n\u001b[0;32m    110\u001b[0m mixin_instance\u001b[38;5;241m.\u001b[39m_deserialize \u001b[38;5;241m=\u001b[39m Deserializer(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_models_dict(api_version))\n\u001b[1;32m--> 111\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m mixin_instance\u001b[38;5;241m.\u001b[39manalyze_text(body, show_stats, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\EON\\Lib\\site-packages\\azure\\core\\tracing\\decorator.py:78\u001b[0m, in \u001b[0;36mdistributed_trace.<locals>.decorator.<locals>.wrapper_use_tracer\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m span_impl_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 78\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     80\u001b[0m \u001b[38;5;66;03m# Merge span is parameter is set, but only if no explicit parent are passed\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\EON\\Lib\\site-packages\\azure\\ai\\textanalytics\\_generated\\v2023_04_01\\operations\\_text_analytics_client_operations.py:290\u001b[0m, in \u001b[0;36mTextAnalyticsClientOperationsMixin.analyze_text\u001b[1;34m(self, body, show_stats, **kwargs)\u001b[0m\n\u001b[0;32m    288\u001b[0m request\u001b[38;5;241m.\u001b[39murl \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39mformat_url(request\u001b[38;5;241m.\u001b[39murl, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpath_format_arguments)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m--> 290\u001b[0m pipeline_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39m_pipeline\u001b[38;5;241m.\u001b[39mrun(  \u001b[38;5;66;03m# type: ignore # pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    291\u001b[0m     request,\n\u001b[0;32m    292\u001b[0m     stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    293\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    294\u001b[0m )\n\u001b[0;32m    296\u001b[0m response \u001b[38;5;241m=\u001b[39m pipeline_response\u001b[38;5;241m.\u001b[39mhttp_response\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\EON\\Lib\\site-packages\\azure\\core\\pipeline\\_base.py:230\u001b[0m, in \u001b[0;36mPipeline.run\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    229\u001b[0m first_node \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_impl_policies[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_impl_policies \u001b[38;5;28;01melse\u001b[39;00m _TransportRunner(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transport)\n\u001b[1;32m--> 230\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m first_node\u001b[38;5;241m.\u001b[39msend(pipeline_request)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\EON\\Lib\\site-packages\\azure\\core\\pipeline\\_base.py:86\u001b[0m, in \u001b[0;36m_SansIOHTTPPolicyRunner.send\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 86\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnext\u001b[38;5;241m.\u001b[39msend(request)\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\EON\\Lib\\site-packages\\azure\\core\\pipeline\\_base.py:86\u001b[0m, in \u001b[0;36m_SansIOHTTPPolicyRunner.send\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 86\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnext\u001b[38;5;241m.\u001b[39msend(request)\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n",
      "    \u001b[1;31m[... skipping similar frames: _SansIOHTTPPolicyRunner.send at line 86 (2 times)]\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\EON\\Lib\\site-packages\\azure\\core\\pipeline\\_base.py:86\u001b[0m, in \u001b[0;36m_SansIOHTTPPolicyRunner.send\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 86\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnext\u001b[38;5;241m.\u001b[39msend(request)\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\EON\\Lib\\site-packages\\azure\\core\\pipeline\\policies\\_redirect.py:197\u001b[0m, in \u001b[0;36mRedirectPolicy.send\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    196\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m retryable:\n\u001b[1;32m--> 197\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnext\u001b[38;5;241m.\u001b[39msend(request)\n\u001b[0;32m    198\u001b[0m     redirect_location \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_redirect_location(response)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\EON\\Lib\\site-packages\\azure\\core\\pipeline\\policies\\_retry.py:553\u001b[0m, in \u001b[0;36mRetryPolicy.send\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    552\u001b[0m             \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m--> 553\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[0;32m    554\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\EON\\Lib\\site-packages\\azure\\core\\pipeline\\policies\\_retry.py:531\u001b[0m, in \u001b[0;36mRetryPolicy.send\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    530\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_configure_timeout(request, absolute_timeout, is_response_error)\n\u001b[1;32m--> 531\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnext\u001b[38;5;241m.\u001b[39msend(request)\n\u001b[0;32m    532\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_retry(retry_settings, response):\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\EON\\Lib\\site-packages\\azure\\core\\pipeline\\_base.py:86\u001b[0m, in \u001b[0;36m_SansIOHTTPPolicyRunner.send\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 86\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnext\u001b[38;5;241m.\u001b[39msend(request)\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\EON\\Lib\\site-packages\\azure\\core\\pipeline\\_base.py:86\u001b[0m, in \u001b[0;36m_SansIOHTTPPolicyRunner.send\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 86\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnext\u001b[38;5;241m.\u001b[39msend(request)\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\EON\\Lib\\site-packages\\azure\\core\\pipeline\\_base.py:91\u001b[0m, in \u001b[0;36m_SansIOHTTPPolicyRunner.send\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 91\u001b[0m     _await_result(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_policy\u001b[38;5;241m.\u001b[39mon_response, request, response)\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\EON\\Lib\\site-packages\\azure\\core\\pipeline\\_tools.py:49\u001b[0m, in \u001b[0;36mawait_result\u001b[1;34m(func, *args, **kwargs)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"If func returns an awaitable, raise that this runner can't handle it.\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \n\u001b[0;32m     41\u001b[0m \u001b[38;5;124;03m:param func: The function to run.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;124;03m:raises: TypeError\u001b[39;00m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m---> 49\u001b[0m result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(result, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__await__\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\EON\\Lib\\site-packages\\azure\\ai\\textanalytics\\_policies.py:66\u001b[0m, in \u001b[0;36mQuotaExceededPolicy.on_response\u001b[1;34m(self, request, response)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m403\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m     65\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOut of call volume quota for TextAnalytics F0 pricing tier\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m http_response\u001b[38;5;241m.\u001b[39mtext():\n\u001b[1;32m---> 66\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HttpResponseError(http_response\u001b[38;5;241m.\u001b[39mtext(), response\u001b[38;5;241m=\u001b[39mhttp_response)\n",
      "\u001b[1;31mHttpResponseError\u001b[0m: (403) Out of call volume quota for TextAnalytics F0 pricing tier. Please retry after 12 days. To increase your call volume switch to a paid tier.\nCode: 403\nMessage: Out of call volume quota for TextAnalytics F0 pricing tier. Please retry after 12 days. To increase your call volume switch to a paid tier.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mHttpResponseError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32m<timed exec>:11\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\EON\\Lib\\site-packages\\presidio_analyzer\\analyzer_engine.py:207\u001b[0m, in \u001b[0;36mAnalyzerEngine.analyze\u001b[1;34m(self, text, language, entities, correlation_id, score_threshold, return_decision_process, ad_hoc_recognizers, context, allow_list, nlp_artifacts)\u001b[0m\n\u001b[0;32m    204\u001b[0m     recognizer\u001b[38;5;241m.\u001b[39mis_loaded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;66;03m# analyze using the current recognizer and append the results\u001b[39;00m\n\u001b[1;32m--> 207\u001b[0m current_results \u001b[38;5;241m=\u001b[39m recognizer\u001b[38;5;241m.\u001b[39manalyze(\n\u001b[0;32m    208\u001b[0m     text\u001b[38;5;241m=\u001b[39mtext, entities\u001b[38;5;241m=\u001b[39mentities, nlp_artifacts\u001b[38;5;241m=\u001b[39mnlp_artifacts\n\u001b[0;32m    209\u001b[0m )\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m current_results:\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;66;03m# add recognizer name to recognition metadata inside results\u001b[39;00m\n\u001b[0;32m    212\u001b[0m     \u001b[38;5;66;03m# if not exists\u001b[39;00m\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__add_recognizer_id_if_not_exists(current_results, recognizer)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\EON\\Lib\\site-packages\\presidio_analyzer\\predefined_recognizers\\azure_ai_language.py:120\u001b[0m, in \u001b[0;36mAzureAILanguageRecognizer.analyze\u001b[1;34m(self, text, entities, nlp_artifacts)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m entities:\n\u001b[0;32m    119\u001b[0m     entities \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msupported_entities\n\u001b[1;32m--> 120\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mta_client\u001b[38;5;241m.\u001b[39mrecognize_pii_entities(\n\u001b[0;32m    121\u001b[0m     [text], language\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msupported_language\n\u001b[0;32m    122\u001b[0m )\n\u001b[0;32m    123\u001b[0m results \u001b[38;5;241m=\u001b[39m [doc \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m response \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m doc\u001b[38;5;241m.\u001b[39mis_error]\n\u001b[0;32m    124\u001b[0m recognizer_results \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\EON\\Lib\\site-packages\\azure\\core\\tracing\\decorator.py:78\u001b[0m, in \u001b[0;36mdistributed_trace.<locals>.decorator.<locals>.wrapper_use_tracer\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     76\u001b[0m span_impl_type \u001b[38;5;241m=\u001b[39m settings\u001b[38;5;241m.\u001b[39mtracing_implementation()\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m span_impl_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 78\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     80\u001b[0m \u001b[38;5;66;03m# Merge span is parameter is set, but only if no explicit parent are passed\u001b[39;00m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m merge_span \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m passed_in_parent:\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\EON\\Lib\\site-packages\\azure\\ai\\textanalytics\\_validate.py:79\u001b[0m, in \u001b[0;36mvalidate_multiapi_args.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;66;03m# the latest version is selected, we assume all features supported\u001b[39;00m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m selected_api_version \u001b[38;5;241m==\u001b[39m VERSIONS_SUPPORTED[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]:\n\u001b[1;32m---> 79\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     81\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m version_method_added \u001b[38;5;129;01mand\u001b[39;00m version_method_added \u001b[38;5;241m!=\u001b[39m selected_api_version \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m     82\u001b[0m         VERSIONS_SUPPORTED\u001b[38;5;241m.\u001b[39mindex(selected_api_version) \u001b[38;5;241m<\u001b[39m VERSIONS_SUPPORTED\u001b[38;5;241m.\u001b[39mindex(version_method_added):\n\u001b[0;32m     83\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     84\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclient\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not available in API version \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     85\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mselected_api_version\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Use service API version \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mversion_method_added\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m or newer.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     86\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\EON\\Lib\\site-packages\\azure\\ai\\textanalytics\\_text_analytics_client.py:500\u001b[0m, in \u001b[0;36mTextAnalyticsClient.recognize_pii_entities\u001b[1;34m(self, documents, categories_filter, disable_service_logs, domain_filter, language, model_version, show_stats, string_index_type, **kwargs)\u001b[0m\n\u001b[0;32m    485\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[0;32m    486\u001b[0m         List[Union[RecognizePiiEntitiesResult, DocumentError]],\n\u001b[0;32m    487\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39mentities_recognition_pii(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    497\u001b[0m         )\n\u001b[0;32m    498\u001b[0m     )\n\u001b[0;32m    499\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HttpResponseError \u001b[38;5;28;01mas\u001b[39;00m error:\n\u001b[1;32m--> 500\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m process_http_response_error(error)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\EON\\Lib\\site-packages\\azure\\ai\\textanalytics\\_response_handlers.py:63\u001b[0m, in \u001b[0;36mprocess_http_response_error\u001b[1;34m(error)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m404\u001b[39m:\n\u001b[0;32m     62\u001b[0m     raise_error \u001b[38;5;241m=\u001b[39m ResourceNotFoundError\n\u001b[1;32m---> 63\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m raise_error(response\u001b[38;5;241m=\u001b[39merror\u001b[38;5;241m.\u001b[39mresponse, error_format\u001b[38;5;241m=\u001b[39mCSODataV4Format) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merror\u001b[39;00m\n",
      "\u001b[1;31mHttpResponseError\u001b[0m: (403) Out of call volume quota for TextAnalytics F0 pricing tier. Please retry after 12 days. To increase your call volume switch to a paid tier.\nCode: 403\nMessage: Out of call volume quota for TextAnalytics F0 pricing tier. Please retry after 12 days. To increase your call volume switch to a paid tier."
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Run Presidio Analyzer on texts, perform conflict resolution and address merging and return dict of results (predictions_dict)\n",
    "# that has the correct format for later calculating the performance scores\n",
    "\n",
    "anonymizer = AnonymizerEngine()\n",
    "\n",
    "predictions_dict = {}\n",
    "predictions_dict_recognizer_format = {}\n",
    "\n",
    "for key, value in original_texts_dict.items():\n",
    "\n",
    "  pred = analyzer_eon.analyze(\n",
    "                              text = value,\n",
    "                              language = \"de\",\n",
    "                              entities = entities_to_detect,\n",
    "                              score_threshold = 0.6,\n",
    "                              )\n",
    "\n",
    "  # Remove conflicts when overlapping entities were detected\n",
    "  pred_after_conflicts = anonymizer._remove_conflicts_and_get_text_manipulation_data(\n",
    "                                                                                    analyzer_results = pred,\n",
    "                                                                                    conflict_resolution = ConflictResolutionStrategy\n",
    "                                                                                    )\n",
    "\n",
    "  pred_after_conflicts_sorted = sorted(pred_after_conflicts, key=lambda x: x.start)\n",
    "\n",
    "  # Merge address entities when adjacent\n",
    "  pred_merged = hfp.merge_to_address(\n",
    "                                    self = anonymizer,\n",
    "                                    text = value,\n",
    "                                    analyzer_results = pred_after_conflicts_sorted\n",
    "                                    )\n",
    "\n",
    "  pred_merged_list = hfp.results_recognizer_to_list(pred_merged)\n",
    "\n",
    "  predictions_dict_recognizer_format[key] = pred_merged\n",
    "  predictions_dict[key] = pred_merged_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "32hG5c7oxBpo"
   },
   "source": [
    "# Run Presidio Anonymizer on all texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "v5uwojAuwp29"
   },
   "outputs": [],
   "source": [
    "# Run PresidioAnonymizer\n",
    "# The PresidioAnonymizer takes the results of the PresidioAnalyzer and the original texts as an input and\n",
    "# returns the anonymized text as an output. The operators define how the detected entities should be anonymized.\n",
    "\n",
    "anonymized_texts_dict = {}\n",
    "\n",
    "for key, value in predictions_dict_recognizer_format.items():\n",
    "\n",
    "  anonymized_result = anonymizer.anonymize(\n",
    "                                          text = original_texts_dict[key],\n",
    "                                          analyzer_results = value,\n",
    "                                          operators = {\n",
    "                                                      \"DEFAULT\": OperatorConfig(\"replace\", {\"new_value\": \"<ANONYMIZED>\"}),\n",
    "                                                      \"PERSON\": OperatorConfig(\"replace\", {\"new_value\": \"<PERSON>\"}),\n",
    "                                                      \"LOCATION\": OperatorConfig(\"replace\", {\"new_value\": \"<ORT>\"}),\n",
    "                                                      \"ZAEHLERNR.\": OperatorConfig(\"replace\", {\"new_value\": \"<ZÄHLERNR.>\"}),\n",
    "                                                      \"PHONE_NUMBER\": OperatorConfig(\"replace\", {\"new_value\": \"<TELEFONNR.>\"}),\n",
    "                                                      \"VERTRAGSNR.\": OperatorConfig(\"replace\", {\"new_value\": \"<VERTRAGSNR.>\"}),\n",
    "                                                      \"GESCHAEFTSPARTNERNR.\": OperatorConfig(\"replace\", {\"new_value\": \"<GESCHÄFTSPARTNERNR.>\"}),\n",
    "                                                      \"RECHNUNGSNR.\": OperatorConfig(\"replace\", {\"new_value\": \"<RECHNUNGSNR.>\"}),\n",
    "                                                      \"PLZ\": OperatorConfig(\"replace\", {\"new_value\": \"<PLZ>\"}),\n",
    "                                                      \"STRASSE\": OperatorConfig(\"replace\", {\"new_value\": \"<STRASSE>\"}),\n",
    "                                                      \"PHONENUMBER\": OperatorConfig(\"replace\", {\"new_value\": \"<TELEFONNR.>\"}),\n",
    "                                                      \"EMAIL\": OperatorConfig(\"replace\", {\"new_value\": \"<EMAIL>\"}),\n",
    "                                                      \"ADDRESS\": OperatorConfig(\"replace\", {\"new_value\": \"<ADRESSE>\"}),\n",
    "                                                      \"ADRESSE\": OperatorConfig(\"replace\", {\"new_value\": \"<ADRESSE>\"}),\n",
    "                                                      }\n",
    "                                          )\n",
    "\n",
    "  anonymized_texts_dict[key] = anonymized_result.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1udxvtCKLspV"
   },
   "source": [
    "# Save anonymized texts and predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "IWm823qXzZLD"
   },
   "outputs": [],
   "source": [
    "current_dt = datetime.now(pytz.timezone('Europe/Berlin')).strftime(\"%Y-%m-%d_%H-%M-%S\") # get current datetime for folder and filenames\n",
    "file_ext = \"_presidio\" # set string for filenames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "26LAovEf3aZv"
   },
   "source": [
    "## Save predictions and anonymized texts as .json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_folder_name = os.path.join(\"..\", \"model_results\", current_dt + file_ext)\n",
    "os.makedirs(new_folder_name, exist_ok=True)\n",
    "\n",
    "# Set filenames of json files\n",
    "predictions_dict_filename = os.path.join(new_folder_name, \"predictions_dict_\" + current_dt + file_ext + \".json\")\n",
    "anonymized_texts_dict_filename = os.path.join(new_folder_name, \"anonymized_texts_dict_\" + current_dt + file_ext + \".json\")\n",
    "\n",
    "# Save predictions and anonymized_texts dictionaries as json files\n",
    "with open(predictions_dict_filename, 'w') as predictions_file:\n",
    "    json.dump(predictions_dict, predictions_file)\n",
    "\n",
    "with open(anonymized_texts_dict_filename, 'w') as anonymized_texts_file:\n",
    "    json.dump(anonymized_texts_dict, anonymized_texts_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O8w1s3EK3TdY"
   },
   "source": [
    "## Save all anonymized texts as .txt files on Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "COl37f561R_e"
   },
   "outputs": [],
   "source": [
    "# Set location of the local folder where you want to save the files\n",
    "local_folder_path = \"../data/anonymized_texts\"\n",
    "os.makedirs(local_folder_path, exist_ok=True)  # Ensure the folder exists, create it if it doesn't\n",
    "\n",
    "# Set foldername and filenames for saving data\n",
    "file_ext = \"_GPT\"  # set string for filenames\n",
    "current_dt = datetime.now(pytz.timezone('Europe/Berlin')).strftime(\"%Y-%m-%d_%H-%M-%S\")  # get current datetime for filenames\n",
    "new_folder_name_txt = os.path.join(local_folder_path, current_dt + file_ext)\n",
    "os.makedirs(new_folder_name_txt, exist_ok=True)  # Create a new folder with datetime\n",
    "\n",
    "# Save each file in the local folder\n",
    "for key, value in anonymized_texts_dict.items():\n",
    "    filename = os.path.join(new_folder_name_txt, f\"{key[:-4]}_an.txt\")\n",
    "    file_content = value\n",
    "\n",
    "    # Write the content to a file in the local folder\n",
    "    with open(filename, 'w') as file:\n",
    "        file.write(file_content)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyObeSYPvYNA69/fkFaIwavI",
   "provenance": [
    {
     "file_id": "18Wx9DzqjUYiPydRApib9cgVo644tnrkd",
     "timestamp": 1714382171138
    }
   ]
  },
  "kernelspec": {
   "display_name": "EON",
   "language": "python",
   "name": "eon"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
