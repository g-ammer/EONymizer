{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lHX3Y_YqdEjw"
   },
   "source": [
    "# Remove PII from .txt files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "li89MWQX9vMs"
   },
   "source": [
    "The code is optimized for importing and exporting files from local drive\n",
    "\n",
    "**Setup**\n",
    "- start LM Studio and load a model\n",
    "- set your URL for LM Studio \n",
    "- update your input folder. should contain .txt files to annonymize\n",
    "- update your output folder\n",
    "- enter a system prompt or use the preset\n",
    "\n",
    "**Run Script**\n",
    "\n",
    "if set up correctly you can run all functions from the starting point \"3. Run from all Scripts from here: ...\"\n",
    "\n",
    "**Results**\n",
    "\n",
    "You get the anonymized text and the privacymask as a .json file saved in your defined output folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "50N4cITGIh9u"
   },
   "source": [
    "#1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cCzm2HuPIjaJ",
    "outputId": "4a607783-df44-44ff-9b31-91cb959ce642"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\users\\cptfu\\anaconda3\\envs\\eon\\lib\\site-packages (1.30.3)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\cptfu\\anaconda3\\envs\\eon\\lib\\site-packages (from openai) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\cptfu\\anaconda3\\envs\\eon\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\cptfu\\anaconda3\\envs\\eon\\lib\\site-packages (from openai) (0.27.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\cptfu\\anaconda3\\envs\\eon\\lib\\site-packages (from openai) (2.7.1)\n",
      "Requirement already satisfied: sniffio in c:\\users\\cptfu\\anaconda3\\envs\\eon\\lib\\site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\cptfu\\anaconda3\\envs\\eon\\lib\\site-packages (from openai) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in c:\\users\\cptfu\\anaconda3\\envs\\eon\\lib\\site-packages (from openai) (4.11.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\cptfu\\anaconda3\\envs\\eon\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\cptfu\\anaconda3\\envs\\eon\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\cptfu\\anaconda3\\envs\\eon\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\cptfu\\anaconda3\\envs\\eon\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\cptfu\\anaconda3\\envs\\eon\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\cptfu\\anaconda3\\envs\\eon\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.2 in c:\\users\\cptfu\\anaconda3\\envs\\eon\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.18.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\cptfu\\anaconda3\\envs\\eon\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "# load all packages and dependencies\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "import tqdm\n",
    "import re\n",
    "\n",
    "import openai\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Hivgzo-hfkd4"
   },
   "outputs": [],
   "source": [
    "#acess input folder\n",
    "#this folder must contain .txt files\n",
    "folder_path = \"./Input\"\n",
    "\n",
    "#output will be saved here\n",
    "main_output_folder = './Output'\n",
    " #--folder with txts\n",
    " #--folder with json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a0SOTNc6pFQ_"
   },
   "source": [
    "#2. Enter System Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "UxwVoJhYnubE"
   },
   "outputs": [],
   "source": [
    "# this system prompt sets up the task with examples\n",
    "system_prompt=\"\"\"\n",
    "Du bist ein schlaues und sehr genaues NER erkennungs System. Deine Aufgabe ist es personenbezogene Daten aus Texten zu entfernen. Und mit einer Privacymask zu kennzeichnen.\n",
    "Du gibst den Text genauso aus, wie er eingegeben wurde und ersetzt jedoch alle personenbezogenen Information mit dem passenden Label.\n",
    "Es gibt diese Labels zur Auswahl. Sonstiges ist für alle nicht klar zuordenbare Labels gedacht.\n",
    "\n",
    "\n",
    "#\n",
    "Entity\n",
    "Label\n",
    "1\n",
    "Vorname Nachname\n",
    "<PERSON>\n",
    "2\n",
    "Adresse/ Stadt\n",
    "<ORT>\n",
    "3\n",
    "Telefonnummer\n",
    "<TELEFONNUMMER>\n",
    "4\n",
    "email\n",
    "<EMAIL>\n",
    "5\n",
    "Vertragsnummer\n",
    "<VERTRAGSNUMMER>\n",
    "6\n",
    "Geschäftspartnernummer\n",
    "<GESCHAEFTSPARTNERNUMMER>\n",
    "7\n",
    "Zählernummer\n",
    "<ZAEHLERNUMMER>\n",
    "8\n",
    "Rechnungsnummer\n",
    "<RECHNUNGSNUMMER>\n",
    "9\n",
    "Kontonummer\n",
    "<KONTONUMMER>\n",
    "10\n",
    "Kreditkartennummer\n",
    "<KREDITKARTENNUMMER>\n",
    "11\n",
    "Postleitzahl\n",
    "<PLZ>\n",
    "12\n",
    "Sonstige Nummer\n",
    "<ID>\n",
    "13\n",
    "Sonstiges\n",
    "<ANONYMIZED>\n",
    "14\n",
    "Straße\n",
    "<STRASSE>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Input:\n",
    "Guten Tag,\n",
    "\n",
    "ich hätte eine Frage bezüglich meiner Vertragsnummer 402364821. Wie kann ich Kontakt mit einem Kundenbetreuer aufnehmen, um meinen Vertrag zu besprechen? Die Gesprächsthemen sollten u.a. meine aktuelle Rechnungsnummer 5629342871 und die Abrechnung meines Zählers beinhalten.\n",
    "\n",
    "Mit freundlichen Grüßen,\n",
    "Helmut Schmidt\n",
    "Mauerstraße 12\n",
    "53859 München\n",
    "h.schmidt@example.de\n",
    "+49 175 9823461\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Output:\n",
    "Guten Tag,\n",
    "\n",
    "ich hätte eine Frage bezüglich meiner Vertragsnummer <<402364821&&VERTRAGSNUMMER>>. Wie kann ich Kontakt mit einem Kundenbetreuer aufnehmen, um meinen Vertrag zu besprechen? Die Gesprächsthemen sollten u.a. meine aktuelle Rechnungsnummer <<5629342871&&RECHNUNGSNUMMER>> und die Abrechnung meines Zählers beinhalten.\n",
    "\n",
    "Mit freundlichen Grüßen,\n",
    "<<Helmut Schmidt&&NAME>>\n",
    "<<Mauerstraße 12&&STRASSE>>\n",
    "<<53859&&PLZ>><<München&&ORT>>\n",
    "<<h.schmidt@example.de&&EMAIL>>\n",
    "<<+49 175 9823461&&TELEFON>>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Input:\n",
    "Betreff: Fragen zur Vertragsnummer 401234567 sowie Kundenservice\n",
    "\n",
    "Hallo,\n",
    "ich hätte ein paar Fragen zu meinem Vertrag mit E.ON unter der Nummer 401234567.\n",
    "\n",
    "Erstens, ich habe Probleme mit der monatlichen Verbrauch Sübersicht und die Einschätzung meiner zukünftigen Kosten, könnten Sie bitte das überprüfen?\n",
    "\n",
    "Zweitens, in der letzten Zeit werde ich von E.ON ganz oft angerufen, obwohl ich ausdrücklich gebeten habe, dass ich auf diese Art der Kommunikation verzichten möchte. Wäre es möglich, diese Anrufe zu beenden und die Kommunikation ausschließlich per Email aufrechtzuerhalten?\n",
    "\n",
    "Ich freue mich auf eine rasche Rückmeldung.\n",
    "\n",
    "Mit besten Grüßen,\n",
    "\n",
    "Michael König\n",
    "Alte Straße 5\n",
    "81541 München\n",
    "michael.koenig@example.com\n",
    "\n",
    "\n",
    "\n",
    "Output:\n",
    "Betreff: Fragen zur Vertragsnummer <<401234567&&VERTRAGSNUMMER>> sowie Kundenservice\n",
    "Hallo,\n",
    "ich hätte ein paar Fragen zu meinem Vertrag mit E.ON unter der Nummer <<401234567&&VERTRAGSNUMMER>>.\n",
    "Erstens, ich habe Probleme mit der monatlichen Verbrauchsübersicht und der Einschätzung meiner zukünftigen Kosten, könnten Sie bitte das überprüfen?\n",
    "Zweitens, in der letzten Zeit werde ich von E.ON ganz oft angerufen, obwohl ich ausdrücklich gebeten habe, dass ich auf diese Art der Kommunikation verzichten möchte. Wäre es möglich, diese Anrufe zu beenden und die Kommunikation ausschließlich per Email aufrechtzuerhalten?\n",
    "Ich freue mich auf eine rasche Rückmeldung.\n",
    "Mit besten Grüßen,\n",
    "<<Michael König&&PERSON>>\n",
    "<<Alte Straße 5&&STRASSE>>\n",
    "<<81541&&PLZ>><<München&&ORT>>\n",
    "<<michael.koenig@example.com&&EMAIL>>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Input:\n",
    "Guten Tag,\n",
    "ich hoffe, Ihnen geht es gut. Mein Name ist Michael Schäfer und ich habe vor Kurzem einen Stromvertrag bei E.ON abgeschlossen. Leider habe ich einige Fragen zur Abrechnung, die ich nicht auf Ihrer Webseite klären konnte.\n",
    "Die Vertragsnummer ist 402587690 und meine Geschäftspartnernummer lautet 200987654. Die Rechnungsnummer meiner aktuellen Abrechnung ist 1234567890.\n",
    "Könnten Sie mir bitte erklären, wie sich der monatliche Abschlag zusammensetzt? Ich bin mir nicht sicher, was die einzelnen Posten auf meiner Rechnung bedeuten.\n",
    "Haben Sie außerdem eine Empfehlung, wie ich meinen Verbrauch besser kontrollieren und möglicherweise verringern kann?\n",
    "Ich freue mich auf Ihre Antwort.\n",
    "Vielen Dank und beste Grüße,\n",
    "Michael Schäfer\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Output:\n",
    "\n",
    "Guten Tag,\n",
    "ich hoffe, Ihnen geht es gut. Mein Name ist <<Michael Schäfer&&PERSON>> und ich habe vor Kurzem einen Stromvertrag bei E.ON abgeschlossen. Leider habe ich einige Fragen zur Abrechnung, die ich nicht auf Ihrer Webseite klären konnte.\n",
    "Die Vertragsnummer ist <<402587690&&VERTRAGSNUMMER>> und meine Geschäftspartnernummer lautet <<200987654&&GESCHAEFTSPARTNERNUMMER>>. Die Rechnungsnummer meiner aktuellen Abrechnung ist <<1234567890&&RECHNUNGSNUMMER>>.\n",
    "Könnten Sie mir bitte erklären, wie sich der monatliche Abschlag zusammensetzt? Ich bin mir nicht sicher, was die einzelnen Posten auf meiner Rechnung bedeuten.\n",
    "Haben Sie außerdem eine Empfehlung, wie ich meinen Verbrauch besser kontrollieren und möglicherweise verringern kann?\n",
    "Ich freue mich auf Ihre Antwort.\n",
    "Vielen Dank und beste Grüße,\n",
    "<<Michael Schäfer&&PERSON>>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Input:\n",
    "Sehr geehrte Damen und Herren,\n",
    "\n",
    "ich bin Kunde bei E.ON mit der Vertragsnummer 232456789123 und habe eine Frage bezüglich meines Kundenkontos. Wie kann ich einen neuen Kundenberater beantragen? Ich wäre Ihnen sehr dankbar, wenn Sie mir diese Information zukommen lassen könnten.\n",
    "\n",
    "Vielen Dank im Voraus für Ihre Hilfe.\n",
    "\n",
    "Mit freundlichen Grüßen,\n",
    "\n",
    "Alexander Schmidt\n",
    "Am Musterweg 4\n",
    "12345 Musterstadt\n",
    "alex.schmidt@mustermail.de\n",
    "Tel: 0176 12345678\n",
    "\n",
    "Output:\n",
    "\n",
    "Sehr geehrte Damen und Herren,\n",
    "ich bin Kunde bei E.ON mit der Vertragsnummer <<232456789123&&VERTRAGSNUMMER>> und habe eine Frage bezüglich meines Kundenkontos. Wie kann ich einen neuen Kundenberater beantragen? Ich wäre Ihnen sehr dankbar, wenn Sie mir diese Information zukommen lassen könnten.\n",
    "Vielen Dank im Voraus für Ihre Hilfe.\n",
    "Mit freundlichen Grüßen,\n",
    "<<Alexander Schmidt&&PERSON>>\n",
    "<<Am Musterweg 4&&STRASSE>>\n",
    "<<12345&&PLZ>><<Musterstadt&&ORT>>\n",
    "<<alex.schmidt@mustermail.de&&EMAIL>>\n",
    "Tel: <<0176 12345678&&TELEFONNUMMER>>\n",
    "\n",
    "\n",
    "\n",
    "Input\n",
    "Guten Tag,\n",
    "\n",
    "\n",
    "mein Name ist Sabine Müller und ich bin Kunde bei E.ON mit der Vertragsnummer 401234567. Ich habe eine Frage bezüglich des Kundenservice. Vor einigen Tagen hatte ich ein Problem mit meiner Stromversorgung und wollte Kontakt mit einem Kundenberater aufnehmen. Leider konnte ich niemanden erreichen.\n",
    "\n",
    "\n",
    "Könnten Sie mir bitte mitteilen, wie ich am besten einen Kundenbetreuer erreichen kann, falls ich zukünftig wieder auf Probleme stoße? Gibt es eine spezielle Telefonnummer oder E-Mail-Adresse, die ich verwenden kann? Oder kann ich auch über das Kundenportal auf Ihrer Webseite einen Kundenberater kontaktieren?\n",
    "\n",
    "\n",
    "Ich würde mich über eine schnelle Rückmeldung freuen.\n",
    "\n",
    "\n",
    "Vielen Dank im Voraus.\n",
    "\n",
    "\n",
    "Mit freundlichen Grüßen,\n",
    "Sabine Müller\n",
    "Sabine.Mueller@gmail.com\n",
    "Am Sonnenhang 34, 12345 Musterstadt\n",
    "Tel: 0176 12345678\n",
    "\n",
    "Output\n",
    "Guten Tag,\n",
    "mein Name ist <<Sabine Müller&&PERSON>> und ich bin Kunde bei E.ON mit der Vertragsnummer <<401234567&&VERTRAGSNUMMER>>. Ich habe eine Frage bezüglich des Kundenservice. Vor einigen Tagen hatte ich ein Problem mit meiner Stromversorgung und wollte Kontakt mit einem Kundenberater aufnehmen. Leider konnte ich niemanden erreichen.\n",
    "Könnten Sie mir bitte mitteilen, wie ich am besten einen Kundenbetreuer erreichen kann, falls ich zukünftig wieder auf Probleme stoße? Gibt es eine spezielle Telefonnummer oder E-Mail-Adresse, die ich verwenden kann? Oder kann ich auch über das Kundenportal auf Ihrer Webseite einen Kundenberater kontaktieren?\n",
    "Ich würde mich über eine schnelle Rückmeldung freuen.\n",
    "Vielen Dank im Voraus.\n",
    "Mit freundlichen Grüßen,\n",
    "<<Sabine Müller&&PERSON>>\n",
    "<<Sabine.Mueller@gmail.com&&EMAIL>>\n",
    "<<Am Sonnenhang 34&&STRASSE>>, <<12345&&PLZ>>,\n",
    " <<Musterstadt&&ORT>>\n",
    "Tel: <<0176 12345678&&TELEFONNUMMER>>\n",
    "\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gGjRwKm8z8dQ"
   },
   "source": [
    "#3. Run all Scripts from here: Start Anonymization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u7wSLY_a0QLN"
   },
   "source": [
    "##load all texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "tGbu9JaNaFiG"
   },
   "outputs": [],
   "source": [
    "#load data from google drive and save to numpy array(filename,string)\n",
    "import os\n",
    "import numpy as np\n",
    "def load_text_files_to_numpy_with_filenames(folder_path):\n",
    "    # Initialize an empty list to store text contents along with file names\n",
    "    texts_with_filenames = []\n",
    "\n",
    "    # Walk through all files in the specified folder\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        # Check if the file is a text file\n",
    "        if file_name.endswith('.txt'):\n",
    "            # Construct full file path\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "            # Open and read the content of the text file\n",
    "            with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                content = file.read()\n",
    "                # Append tuple of file name and content\n",
    "                texts_with_filenames.append((file_name, content))\n",
    "\n",
    "    # Convert the list to a numpy array of tuples\n",
    "    texts_with_filenames_np = np.array(texts_with_filenames, dtype=object)\n",
    "    return texts_with_filenames_np\n",
    "\n",
    "\n",
    "folder_path = folder_path #defined at the setup section\n",
    "loaded_texts = load_text_files_to_numpy_with_filenames(folder_path)\n",
    "\n",
    "# Debugging:\n",
    "#loaded_texts[0][0]\n",
    "#type(loaded_texts)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "TtJXTroyI-Vs"
   },
   "outputs": [],
   "source": [
    "#debugging\n",
    "#len(loaded_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CRbR9W7TDW8C"
   },
   "source": [
    "###Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "NjYGtimLEhUS"
   },
   "outputs": [],
   "source": [
    "#extract list of strings from loaded_texts array (filename, inputstring)\n",
    "def extract_input_strings(loaded_texts):\n",
    "    # Initialize the resulting list of strings\n",
    "    resulting_list = []\n",
    "\n",
    "    # Loop starting from the second element (index 1)\n",
    "    for i in range(0, len(loaded_texts)):\n",
    "        # Append the items from the sublist at index 1\n",
    "        # Assuming each element at index 1 is an array-like structure containing strings\n",
    "        resulting_list.append(loaded_texts[i][1])\n",
    "\n",
    "    return resulting_list\n",
    "\n",
    "# The call to the function is commented out as per instructions\n",
    "list_of_input_strings= extract_input_strings(loaded_texts)\n",
    "#len(list_of_input_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "Be37J6rXFQkn"
   },
   "outputs": [],
   "source": [
    "#extract list of filenames from tuple (filename, inputstring)\n",
    "def extract_input_filename(loaded_texts):\n",
    "    # Initialize the resulting list of strings\n",
    "    resulting_list = []\n",
    "\n",
    "    # Loop starting from the second element (index 1)\n",
    "    for i in range(0, len(loaded_texts)):\n",
    "        # Append the items from the sublist at index 1\n",
    "        # Assuming each element at index 1 is an array-like structure containing strings\n",
    "        resulting_list.append(loaded_texts[i][0])\n",
    "\n",
    "    return resulting_list\n",
    "\n",
    "# The call to the function is commented out as per instructions\n",
    "list_of_input_filenames= extract_input_filename(loaded_texts)\n",
    "#list_of_input_filenames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lq4_SyPNJh3R"
   },
   "source": [
    "## LM Studio API Call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "model1=\"TheBloke/SauerkrautLM-Mixtral-8x7B-Instruct-GGUF\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h-qNT35GXFd7",
    "outputId": "9f14811f-ec45-4659-b880-27fab9953662"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing texts:   0%|                                                                          | 0/3 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "# dont change here, if you want all text to be scanned\n",
    "num_of_texts_to_scan = 3 #len(loaded_texts) # num of chatgpt request iterations musst be same lenght as truth json\n",
    "\n",
    "# Configuration for OpenAI client\n",
    "# Point to the local server\n",
    "# use ip route to get the right ip address\n",
    "client = OpenAI(base_url=\"http://localhost:4502/v1\", api_key=\"lm-studio\")\n",
    "\n",
    "\n",
    "def gpt_request(text_input):\n",
    "    # Assuming system_prompt is predefined somewhere in your code\n",
    "    response = client.chat.completions.create(\n",
    "        model=model1,\n",
    "        temperature = 0,\n",
    "        messages=[\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": text_input}],\n",
    "        seed=42)\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "\n",
    "def process_texts(texts):\n",
    "    responses = []\n",
    "    # Wrap the loop with tqdm for a progress bar\n",
    "    for text in tqdm.tqdm(texts[:num_of_texts_to_scan], desc=\"Processing texts\"):\n",
    "        response = gpt_request(text)\n",
    "        responses.append(response)\n",
    "    # Convert the list of responses into a NumPy array\n",
    "    response_array = np.array(responses)\n",
    "    return response_array\n",
    "\n",
    "\n",
    "response_array = process_texts(list_of_input_strings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mxHowY4pFsh1"
   },
   "outputs": [],
   "source": [
    "#for debugging\n",
    "#response_array[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7AxP1xhxgwRq"
   },
   "source": [
    "\n",
    "\n",
    "##Prepare output data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "id": "EdwxQKWh5XdG",
    "outputId": "926ced6f-3f60-4180-af56-ded808ef5c4e"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def create_dataframe_from_lists(response_array, list_of_input_strings, list_of_input_filenames):\n",
    "    # Find the minimum length to slice all lists equally without index errors\n",
    "    min_length = min(len(response_array), len(list_of_input_strings), len(list_of_input_filenames), 1010)\n",
    "\n",
    "    # Creating a dictionary where each sliced list becomes a column in the DataFrame\n",
    "    data = {\n",
    "        'output': response_array[:min_length],\n",
    "        'input': list_of_input_strings[:min_length],\n",
    "        'pred_filename': list_of_input_filenames[:min_length],\n",
    "        'system_prompt': system_prompt\n",
    "    }\n",
    "\n",
    "    # Creating the DataFrame using the dictionary\n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "\n",
    "df = create_dataframe_from_lists(response_array, list_of_input_strings, list_of_input_filenames)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R2_4v29n5WDu"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EWLtzHqoM4AO"
   },
   "source": [
    "## create prediction_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jPxxGubDRLfz"
   },
   "outputs": [],
   "source": [
    "#create a new column and create a dict with entity_type, and entitiy_value\n",
    "#find values based on pattes\n",
    "\n",
    "\n",
    "# Function to extract labeled values\n",
    "def extract_labeled_values(text):\n",
    "    # Regex to match content between << and >>\n",
    "    pattern = r\"<<(.*?)&&(.*?)>>\"\n",
    "\n",
    "    # Find all matches in the text\n",
    "    matches = re.findall(pattern, text)\n",
    "\n",
    "    # Create a list of dictionaries from the matches\n",
    "    label_value_list = [{'entity_type': match[1], 'entity_value': match[0]} for match in matches]\n",
    "\n",
    "    return label_value_list\n",
    "\n",
    "# Create a new column with the extracted label-value list\n",
    "df['pred_dict'] = df['output'].apply(extract_labeled_values)\n",
    "\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vjDxQTERNBzx"
   },
   "source": [
    "### calculate START index of predicted entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bAePs2noR-5A"
   },
   "outputs": [],
   "source": [
    "#find start and stop index of each entity\n",
    "\n",
    "#find each pred_value starting index\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def update_unique_pred_start_indices(data, text):\n",
    "    # Check if data is empty, return an empty dict immediately\n",
    "    if not data:\n",
    "        return data\n",
    "\n",
    "    # Dictionary to hold all matches for each value\n",
    "    all_matches = {}\n",
    "    # Dictionary to track the next available index for each value\n",
    "    next_available_index = {}\n",
    "\n",
    "    # First, find all matches for each unique value\n",
    "    for item in data:\n",
    "        value = item['entity_value']\n",
    "        if value not in all_matches:\n",
    "            regex = r'\\b' + re.escape(value) + r'\\b'\n",
    "            all_matches[value] = [match.start() for match in re.finditer(regex, text)]\n",
    "            next_available_index[value] = 0  # Initialize the index tracker for each unique value\n",
    "\n",
    "    # Next, assign the first available match index to each item in data\n",
    "    for item in data:\n",
    "        value = item['entity_value']\n",
    "        matches = all_matches[value]\n",
    "        index = next_available_index[value]\n",
    "\n",
    "        if index < len(matches):\n",
    "            item['start'] = matches[index]\n",
    "            next_available_index[value] += 1  # Move to the next index for the next occurrence\n",
    "        else:\n",
    "            # Optionally handle the case where there are more items than matches (not expected)\n",
    "            item['start'] = None\n",
    "\n",
    "    return data\n",
    "\n",
    "# Example DataFrame and applying the function\n",
    "# df = pd.DataFrame({'dict_start': [[{'pred_value': 'example'}]], 'text': ['This is an example text for example usage.']})\n",
    "df['dict_start_index'] = df.apply(lambda row: update_unique_pred_start_indices(row['pred_dict'], row['input']), axis=1)\n",
    "#df['dict_start_index'].iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MFozj9xTPNZC"
   },
   "source": [
    "### calc END index of predicted entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PQ7HIb9uSslU"
   },
   "outputs": [],
   "source": [
    "#calculate end index of predicted value\n",
    "\n",
    "def add_pred_end_to_dicts(pred_dicts):\n",
    "    \"\"\" Function to add 'pred_end' key to each dictionary in a list, calculated from 'pred_start' and the length of 'pred_value'. \"\"\"\n",
    "    updated_dicts = []\n",
    "    for entry in pred_dicts:\n",
    "        if 'start' in entry and entry['start'] is not None:  # Ensure 'pred_start' exists and is not None\n",
    "            entry['end'] = entry['start'] + len(entry['entity_value'])\n",
    "        updated_dicts.append(entry)\n",
    "    return updated_dicts\n",
    "\n",
    "# Assuming df is your DataFrame and 'dict_start' is the column with lists of dictionaries\n",
    "df['pred_dict_start_end'] = df['dict_start_index'].apply(lambda x: add_pred_end_to_dicts(x) if x is not None else None)\n",
    "\n",
    "# Now, let's see the updated DataFrame\n",
    "#df['pred_dict_start_end'].iloc[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "blBPzUH-QUeo"
   },
   "source": [
    "### extract a dictionary from the df with a list of dicts\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aFiox7sRQyll"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Create the new list of dictionaries with filename and list of entities\n",
    "output_dict= []\n",
    "for _, row in df.iterrows():\n",
    "    new_dict = {\n",
    "        row['pred_filename'] : row['pred_dict_start_end'],\n",
    "    }\n",
    "    output_dict.append(new_dict)\n",
    "\n",
    "#output_dict[1:2]  # New list of dictionaries with filename and entity data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6EITttvFCnUR"
   },
   "outputs": [],
   "source": [
    "resulting_dict = {}\n",
    "\n",
    "# Iterate over each dictionary in the list\n",
    "for data in output_dict:\n",
    "    for key, value in data.items():\n",
    "        # Add the key and its corresponding list of dictionaries to the output dictionary\n",
    "        resulting_dict[key] = value\n",
    "\n",
    "#resulting_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HgVJnmkPxZWU"
   },
   "source": [
    "##save output to folder .txt and .json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a8p9D5pZaoO7"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "def dataframe_to_text_files_in_drive(df, output_folder):\n",
    "    txt_folder_path = os.path.join(output_folder, 'txt')\n",
    "\n",
    "    # Ensure the necessary columns exist\n",
    "    if 'pred_filename' not in df.columns or 'output' not in df.columns:\n",
    "        raise ValueError(\"DataFrame must contain 'pred_filename' and 'output' columns.\")\n",
    "\n",
    "    # Create the txt subdirectory if it does not exist\n",
    "    os.makedirs(txt_folder_path, exist_ok=True)\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        # Construct the full path for the file within the txt subdirectory\n",
    "        full_path = os.path.join(txt_folder_path, f\"{row['pred_filename']}\")\n",
    "\n",
    "        # Write the output to the file\n",
    "        with open(full_path, 'w', encoding='utf-8') as file:\n",
    "            file.write(str(row['output']))\n",
    "\n",
    "def save_predictions_as_json(predictions_dict, output_folder):\n",
    "    json_folder_path = os.path.join(output_folder, 'json')\n",
    "\n",
    "    # Create the json subdirectory if it does not exist\n",
    "    os.makedirs(json_folder_path, exist_ok=True)\n",
    "\n",
    "    # Get the current datetime and format it for file naming\n",
    "    current_dt = datetime.now().strftime(\"%Y-%m-%d_%H-%M\")\n",
    "    filename = f\"predictions_dict_{current_dt}.json\"\n",
    "    full_path = os.path.join(json_folder_path, filename)\n",
    "\n",
    "    # Save predictions dictionary as a JSON file\n",
    "    with open(full_path, 'w') as file:\n",
    "        json.dump(predictions_dict, file)\n",
    "\n",
    "# Get the current datetime and create a timestamped subdirectory\n",
    "current_dt = datetime.now().strftime(\"%Y-%m-%d_%H-%M\")\n",
    "output_folder = os.path.join(main_output_folder, current_dt)\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Call functions with the correct folder\n",
    "dataframe_to_text_files_in_drive(df, output_folder)\n",
    "save_predictions_as_json(resulting_dict, output_folder)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "vjDxQTERNBzx",
    "MFozj9xTPNZC"
   ],
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
